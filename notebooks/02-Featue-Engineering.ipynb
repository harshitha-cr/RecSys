{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e428cfb-be67-45bd-9ff2-e010efc768e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb16235b-92ad-4723-b5ec-106f0d70ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/electronics_sample_2M.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c62178-764c-45be-acaf-0b1e2b9b73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   reviewerID      object \n",
      " 1   asin            object \n",
      " 2   overall         float32\n",
      " 3   unixReviewTime  int64  \n",
      " 4   title           object \n",
      " 5   brand           object \n",
      " 6   categories      object \n",
      "dtypes: float32(1), int64(1), object(5)\n",
      "memory usage: 99.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHAGVEUWD2IRJFPCJLOAYSJ7XNLQ</td>\n",
       "      <td>B008YQAG5Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1393181267000</td>\n",
       "      <td>HP BD-R DL 6X 50GB Double Layer 10 Pack in Spi...</td>\n",
       "      <td>HP</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHYKM5KHAJNN3KQ2EXO25LCCKDFA</td>\n",
       "      <td>B0711V1WXC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1524659491257</td>\n",
       "      <td>Fintie Slim Case for Amazon Fire 7 Tablet (Pre...</td>\n",
       "      <td>Fintie</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Tablet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHZC5B3S7CRPM5S476EIQJKWUS6Q</td>\n",
       "      <td>B00DOHVUIM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1414421305000</td>\n",
       "      <td>Kuzy Compatible with MacBook Keyboard Cover fo...</td>\n",
       "      <td>Kuzy</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGRTA2KJTZWKSFVLMSK2K7RGAKMQ</td>\n",
       "      <td>B000BNY64C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1376084786000</td>\n",
       "      <td>STK BP-511a BP-511 2 Pack Battery for Canon Re...</td>\n",
       "      <td>SterlingTek</td>\n",
       "      <td>[Electronics, Camera &amp; Photo, Accessories, Bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEYUTNEKMD56ZZQ3ZC7XOJDHGRLQ</td>\n",
       "      <td>B0BT9MK3XK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1613463323771</td>\n",
       "      <td>Nulaxy Tablet Stand, Fully Adjustable Foldable...</td>\n",
       "      <td>Nulaxy</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Tablet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     reviewerID        asin  overall  unixReviewTime  \\\n",
       "0  AHAGVEUWD2IRJFPCJLOAYSJ7XNLQ  B008YQAG5Q      5.0   1393181267000   \n",
       "1  AHYKM5KHAJNN3KQ2EXO25LCCKDFA  B0711V1WXC      2.0   1524659491257   \n",
       "2  AHZC5B3S7CRPM5S476EIQJKWUS6Q  B00DOHVUIM      5.0   1414421305000   \n",
       "3  AGRTA2KJTZWKSFVLMSK2K7RGAKMQ  B000BNY64C      4.0   1376084786000   \n",
       "4  AEYUTNEKMD56ZZQ3ZC7XOJDHGRLQ  B0BT9MK3XK      5.0   1613463323771   \n",
       "\n",
       "                                               title        brand  \\\n",
       "0  HP BD-R DL 6X 50GB Double Layer 10 Pack in Spi...           HP   \n",
       "1  Fintie Slim Case for Amazon Fire 7 Tablet (Pre...       Fintie   \n",
       "2  Kuzy Compatible with MacBook Keyboard Cover fo...         Kuzy   \n",
       "3  STK BP-511a BP-511 2 Pack Battery for Canon Re...  SterlingTek   \n",
       "4  Nulaxy Tablet Stand, Fully Adjustable Foldable...       Nulaxy   \n",
       "\n",
       "                                          categories  \n",
       "0  [Electronics, Computers & Accessories, Compute...  \n",
       "1  [Electronics, Computers & Accessories, Tablet ...  \n",
       "2  [Electronics, Computers & Accessories, Compute...  \n",
       "3  [Electronics, Camera & Photo, Accessories, Bat...  \n",
       "4  [Electronics, Computers & Accessories, Tablet ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fbbfd-4bd7-4ac7-91b8-868ac56147e1",
   "metadata": {},
   "source": [
    "## Target Variable (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de3be19-da6c-4df9-afda-3ce5d6e2fdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "positive\n",
      "1    0.800894\n",
      "0    0.199106\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1 if 'overall' is >= 4.0, and 0 otherwise.\n",
    "df['positive'] = (df['overall'] >= 4.0).astype(int)\n",
    "\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['positive'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374323bd-3b3d-41fa-8614-80fa47f8d6d8",
   "metadata": {},
   "source": [
    "## Light Feature Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6fcac9-55f5-4151-9631-d52bbb2d53a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1645\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_title = df['title'].isnull().sum()\n",
    "missing_brand = df['brand'].isnull().sum()\n",
    "null_categories = df['categories'].isnull().sum()\n",
    "\n",
    "print(missing_title)\n",
    "print(missing_brand)\n",
    "print(null_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b417fe7-d937-40ae-8e44-0fb019b3de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls for our text/categorical features\n",
    "# print(\"\\nChecking and filling null values...\")\n",
    "# df['brand'] = df['brand'].fillna('Unknown')\n",
    "\n",
    "# print(\"Feature cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427f8355-148e-4dc8-9042-223f754a1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_brand = df['brand'].isnull().sum()\n",
    "# print(missing_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027e56d9-31ed-4121-b3fc-d2b2ea20705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   reviewerID      object \n",
      " 1   asin            object \n",
      " 2   overall         float32\n",
      " 3   unixReviewTime  int64  \n",
      " 4   title           object \n",
      " 5   brand           object \n",
      " 6   categories      object \n",
      " 7   positive        int64  \n",
      "dtypes: float32(1), int64(2), object(5)\n",
      "memory usage: 114.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c085a6d-e540-480d-b4be-708ec7976a1c",
   "metadata": {},
   "source": [
    "## Time-Based Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c578bb4e-4cc8-4409-a374-d0787092c085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting 2000000 rows by 'unixReviewTime'...\n",
      "Sorting complete.\n",
      "Splitting data into train, validation, and test sets...\n",
      "\n",
      "Split complete. Data shapes:\n",
      "Train set:      (1600000, 8)\n",
      "Validation set: (200000, 8)\n",
      "Test set:       (200000, 8)\n"
     ]
    }
   ],
   "source": [
    "# 1. Sort the entire DataFrame by time\n",
    "print(f\"Sorting {len(df)} rows by 'unixReviewTime'...\")\n",
    "df_sorted = df.sort_values(by='unixReviewTime')\n",
    "print(\"Sorting complete.\")\n",
    "\n",
    "# 2. Calculate split indices\n",
    "total_rows = len(df_sorted)\n",
    "train_end = int(total_rows * 0.8)  # 80% for training\n",
    "val_end = int(total_rows * 0.9)    # 10% for validation (from 80% to 90%)\n",
    "# The last 10% is automatically for testing\n",
    "\n",
    "# 3. Create the splits using iloc (index-based slicing)\n",
    "print(\"Splitting data into train, validation, and test sets...\")\n",
    "train_df = df_sorted.iloc[:train_end]\n",
    "val_df = df_sorted.iloc[train_end:val_end]\n",
    "test_df = df_sorted.iloc[val_end:]\n",
    "\n",
    "# 4. Verify the splits\n",
    "print(\"\\nSplit complete. Data shapes:\")\n",
    "print(f\"Train set:      {train_df.shape}\")\n",
    "print(f\"Validation set: {val_df.shape}\")\n",
    "print(f\"Test set:       {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b8415c-5a00-4e2b-8111-3b9d766c4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time boundaries:\n",
      "Training data ends at:   2021-03-03 04:11:50.559000\n",
      "Validation data starts at: 2021-03-03 04:12:34.086000\n",
      "Test data starts at:     2022-04-04 15:16:48.134000\n",
      "Test data ends at:     2023-09-10 22:15:13.085000\n"
     ]
    }
   ],
   "source": [
    "# Check the time boundaries\n",
    "print(\"\\nTime boundaries:\")\n",
    "print(f\"Training data ends at:   {pd.to_datetime(train_df['unixReviewTime'].max(), unit='ms')}\")\n",
    "print(f\"Validation data starts at: {pd.to_datetime(val_df['unixReviewTime'].min(), unit='ms')}\")\n",
    "print(f\"Test data starts at:     {pd.to_datetime(test_df['unixReviewTime'].min(), unit='ms')}\")\n",
    "print(f\"Test data ends at:     {pd.to_datetime(test_df['unixReviewTime'].max(), unit='ms')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a7af3-31e2-413f-a9a4-92a5dd49b61b",
   "metadata": {},
   "source": [
    "## Saving train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb65846-8d31-4815-b180-ead3a1789861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data splits to Parquet...\n",
      "Train, validation, and test sets saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving data splits to Parquet...\")\n",
    "\n",
    "# Save each DataFrame to its own file\n",
    "train_df.to_parquet('../data/train_df.parquet', index=False)\n",
    "val_df.to_parquet('../data/val_df.parquet', index=False)\n",
    "test_df.to_parquet('../data/test_df.parquet', index=False)\n",
    "\n",
    "print(\"Train, validation, and test sets saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd1431-b9b1-4407-8089-7643992c017d",
   "metadata": {},
   "source": [
    "## Integer Mapping for categorial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf15035-85f2-4f2e-8c75-baeb8b6366ac",
   "metadata": {},
   "source": [
    "* convert our main categorical columns (reviewerID, asin, brand annd categories) into integer IDs.\n",
    "\n",
    "The correct way is to:\n",
    "\n",
    "Fit: Create the mapping (e.g., {'Sony': 1, 'Apple': 2}) using only train_df.\n",
    "\n",
    "ID 0: \"This is a specific brand/item, but I haven't learned its personality yet.\" Value is valid but unseen (Cold Start)\n",
    "ID 1: \"This item has NO brand info at all.\" means Value is NaN / None\n",
    "\n",
    "Transform: Use that same mapping on train_df, val_df, and test_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadee103-d208-4d11-9160-06e0c6ba6abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting categorical feature engineering (Robust Method)...\n",
      "Creating mapping for: reviewerID\n",
      "Saved mapping with 915325 entries to ../data/user_mapping.json\n",
      "Creating mapping for: asin\n",
      "Saved mapping with 235824 entries to ../data/item_mapping.json\n",
      "Creating mapping for: brand\n",
      "Saved mapping with 31325 entries to ../data/brand_mapping.json\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting categorical feature engineering (Robust Method)...\")\n",
    "\n",
    "# --- 1. Helper to Build Mappings (Ignoring NaNs) ---\n",
    "def create_and_save_mapping(dataframe, column_name, output_filename):\n",
    "    \"\"\"\n",
    "    Creates a vocabulary from a DataFrame column.\n",
    "    - Ignores NaN values when building the list.\n",
    "    - Reserves ID 0 for <UNKNOWN> (unseen values).\n",
    "    - Reserves ID 1 for <MISSING> (NaN values).\n",
    "    - Starts real IDs at 2.\n",
    "    \"\"\"\n",
    "    print(f\"Creating mapping for: {column_name}\")\n",
    "    \n",
    "    # Get unique values, BUT explicitly drop NaNs first\n",
    "    unique_values = dataframe[column_name].dropna().unique()\n",
    "    \n",
    "    # Create the mapping starting at ID 2\n",
    "    mapping = {val: i+2 for i, val in enumerate(unique_values)}\n",
    "    \n",
    "    # Add our special tokens\n",
    "    mapping['<UNKNOWN>'] = 0 \n",
    "    mapping['<MISSING>'] = 1 \n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(output_filename, 'w') as f:\n",
    "        # We need to convert numpy types to standard python types for JSON\n",
    "        # (e.g. numpy.int64 -> int)\n",
    "        def convert(o):\n",
    "            if isinstance(o, np.integer): return int(o)\n",
    "            raise TypeError\n",
    "        json.dump(mapping, f, default=convert)\n",
    "        \n",
    "    print(f\"Saved mapping with {len(mapping)} entries to {output_filename}\")\n",
    "    return mapping\n",
    "\n",
    "# --- 2. Create mappings (from TRAIN only) ---\n",
    "user_mapping = create_and_save_mapping(train_df, 'reviewerID', '../data/user_mapping.json')\n",
    "item_mapping = create_and_save_mapping(train_df, 'asin', '../data/item_mapping.json')\n",
    "brand_mapping = create_and_save_mapping(train_df, 'brand', '../data/brand_mapping.json')\n",
    "\n",
    "\n",
    "# --- 3. Helper to Apply Mappings (Handling NaNs) ---\n",
    "def apply_mapping_robust(dataframe, column_name, mapping):\n",
    "    \"\"\"\n",
    "    Applies mapping with explicit logic:\n",
    "    - If NaN -> Return 1 (<MISSING>)\n",
    "    - If in Map -> Return ID\n",
    "    - If Not in Map -> Return 0 (<UNKNOWN>)\n",
    "    \"\"\"\n",
    "    print(f\"Applying mapping to: {column_name}\")\n",
    "    \n",
    "    def get_id(val):\n",
    "        # Case 1: Value is NaN / None\n",
    "        if pd.isna(val) or val == \"\":\n",
    "            return mapping['<MISSING>'] # ID 1\n",
    "        \n",
    "        # Case 2: Value is in our vocabulary\n",
    "        if val in mapping:\n",
    "            return mapping[val]\n",
    "        \n",
    "        # Case 3: Value is valid but unseen (Cold Start)\n",
    "        return mapping['<UNKNOWN>'] # ID 0\n",
    "\n",
    "    return dataframe[column_name].apply(get_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9fad892-43fe-4a4f-a56a-85e202ffaa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating independent copies of the data splits...\n"
     ]
    }
   ],
   "source": [
    "# --- FIX for SettingWithCopyWarning ---\n",
    "print(\"Creating independent copies of the data splits...\")\n",
    "\n",
    "# The .copy() method creates a brand new object in memory\n",
    "train_df = train_df.copy()\n",
    "val_df = val_df.copy()\n",
    "test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb65246-6d75-4ba8-a6e7-ff42dd26e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying mappings to train, val, and test sets...\n",
      "Applying mapping to: reviewerID\n",
      "Applying mapping to: asin\n",
      "Applying mapping to: brand\n",
      "Applying mapping to: reviewerID\n",
      "Applying mapping to: asin\n",
      "Applying mapping to: brand\n",
      "Applying mapping to: reviewerID\n",
      "Applying mapping to: asin\n",
      "Applying mapping to: brand\n",
      "\n",
      "Mapping complete. Checking 'brand_id' for missing values handling:\n",
      "             brand  brand_id\n",
      "1190044         HP         2\n",
      "1236487  Replay Tv         3\n",
      "63617      Olympus         4\n",
      "779636     PHILIPS         5\n",
      "1673857    Olympus         4\n",
      "506328   Microsoft         6\n",
      "1125448    PHILIPS         5\n",
      "862728   Replay Tv         3\n",
      "1402558    Toshiba         7\n",
      "1841846         HP         2\n",
      "\n",
      "Rows with Missing Brand (ID=1) in Train: 1527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. Apply to all splits ---\n",
    "print(\"\\nApplying mappings to train, val, and test sets...\")\n",
    "\n",
    "datasets = [train_df, val_df, test_df]\n",
    "# columns: (new_col_name, old_col_name, mapping_dict)\n",
    "mapping_configs = [\n",
    "    ('user_id', 'reviewerID', user_mapping),\n",
    "    ('item_id', 'asin', item_mapping),\n",
    "    ('brand_id', 'brand', brand_mapping)\n",
    "]\n",
    "\n",
    "for df in datasets:\n",
    "    for new_col, old_col, mapping in mapping_configs:\n",
    "        df[new_col] = apply_mapping_robust(df, old_col, mapping)\n",
    "\n",
    "# --- 5. Verify ---\n",
    "print(\"\\nMapping complete. Checking 'brand_id' for missing values handling:\")\n",
    "# Let's check a row where brand might be missing if you have one, \n",
    "# or just print the first few rows.\n",
    "print(train_df[['brand', 'brand_id']].head(10))\n",
    "\n",
    "# Check if we have any ID=1 (Missing) in the brand_id column\n",
    "missing_count = (train_df['brand_id'] == 1).sum()\n",
    "print(f\"\\nRows with Missing Brand (ID=1) in Train: {missing_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0883d24-8bcf-439d-a28e-f6d6227dbff5",
   "metadata": {},
   "source": [
    "## Task 6: Process Categories\n",
    "Extracts the single best category string from the list.\n",
    "\n",
    "Maps that string to an integer ID (using the same robust logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72e960f3-e0b0-4767-9a98-107ffabbbe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 'categories' processing (NumPy Support Added)...\n",
      "Extracting 'main_category' column...\n",
      "Extraction example:\n",
      "                                                categories  \\\n",
      "1190044  [Electronics, Computers & Accessories, Compute...   \n",
      "1236487  [Electronics, Television & Video, Streaming Me...   \n",
      "63617    [Electronics, Camera & Photo, Film Photography...   \n",
      "779636   [Electronics, Television & Video, Streaming Me...   \n",
      "1673857  [Electronics, Camera & Photo, Digital Cameras,...   \n",
      "\n",
      "                         main_category  \n",
      "1190044                        Webcams  \n",
      "1236487        Streaming Media Players  \n",
      "63617       Point & Shoot Film Cameras  \n",
      "779636         Streaming Media Players  \n",
      "1673857  Point & Shoot Digital Cameras  \n",
      "Creating mapping for: main_category\n",
      "Saved mapping with 1001 entries to ../data/category_mapping.json\n",
      "\n",
      "Applying 'main_category_id' mapping...\n",
      "Applying mapping to: main_category\n",
      "Applying mapping to: main_category\n",
      "Applying mapping to: main_category\n",
      "Category processing complete!\n",
      "                         main_category  main_category_id\n",
      "1190044                        Webcams                 2\n",
      "1236487        Streaming Media Players                 3\n",
      "63617       Point & Shoot Film Cameras                 4\n",
      "779636         Streaming Media Players                 3\n",
      "1673857  Point & Shoot Digital Cameras                 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "print(\"Starting 'categories' processing (NumPy Support Added)...\")\n",
    "\n",
    "def get_most_specific_category(val):\n",
    "    # --- CASE 1: Handle NumPy Arrays (The likely culprit!) ---\n",
    "    if isinstance(val, np.ndarray):\n",
    "        val = val.tolist()\n",
    "    \n",
    "    # --- CASE 2: Handle Strings that look like lists ---\n",
    "    elif isinstance(val, str) and val.startswith('['):\n",
    "        try:\n",
    "            val = ast.literal_eval(val)\n",
    "        except:\n",
    "            return 'Unknown'\n",
    "            \n",
    "    # --- CASE 3: If it's still not a list, fail ---\n",
    "    if not isinstance(val, list):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # --- Now process the List ---\n",
    "    if len(val) == 0:\n",
    "        return 'Unknown'\n",
    "        \n",
    "    try:\n",
    "        # Check for nested list [['Elec', 'Comp']]\n",
    "        # (Parquet sometimes flattens this, so we check carefully)\n",
    "        first_item = val[0]\n",
    "        if isinstance(first_item, list) or isinstance(first_item, np.ndarray):\n",
    "             # It's nested, grab the last sub-list\n",
    "             last_sublist = val[-1]\n",
    "             if len(last_sublist) > 0:\n",
    "                 return last_sublist[-1]\n",
    "             else:\n",
    "                 return 'Unknown'\n",
    "        else:\n",
    "            # It's a simple flat list ['Elec', 'Comp']\n",
    "            return val[-1]\n",
    "    except Exception as e:\n",
    "        return 'Unknown'\n",
    "\n",
    "# --- Apply extraction ---\n",
    "print(\"Extracting 'main_category' column...\")\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df['main_category'] = df['categories'].apply(get_most_specific_category)\n",
    "\n",
    "print(\"Extraction example:\")\n",
    "print(train_df[['categories', 'main_category']].head())\n",
    "\n",
    "# --- Re-run Mapping (Standard Steps) ---\n",
    "category_mapping = create_and_save_mapping(train_df, 'main_category', '../data/category_mapping.json')\n",
    "\n",
    "print(\"\\nApplying 'main_category_id' mapping...\")\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df['main_category_id'] = apply_mapping_robust(df, 'main_category', category_mapping)\n",
    "\n",
    "print(\"Category processing complete!\")\n",
    "print(train_df[['main_category', 'main_category_id']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d371e032-169a-4832-ad19-eb9897daf34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190044    [Electronics, Computers & Accessories, Compute...\n",
      "1236487    [Electronics, Television & Video, Streaming Me...\n",
      "Name: categories, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df['categories'].head(2))\n",
    "# categories column is not a Python list, and it is not a string. It is a NumPy Array (numpy.ndarray)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d555b609-86aa-4a5e-9220-b9cfe3062289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>positive</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1190044</th>\n",
       "      <td>AENJWAP4JGEFZGDCTSX72UQ6M7IQ</td>\n",
       "      <td>B00000JDHV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940168313000</td>\n",
       "      <td>3Com 00371800 HomeConnect PC Digital Camera</td>\n",
       "      <td>HP</td>\n",
       "      <td>[Electronics, Computers &amp; Accessories, Compute...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Webcams</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236487</th>\n",
       "      <td>AHILMS23CHY27DIIEOPI3EHMRXAQ</td>\n",
       "      <td>B00002ST80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>941867224000</td>\n",
       "      <td>ReplayTV 2020 Digital Video Recorder</td>\n",
       "      <td>Replay Tv</td>\n",
       "      <td>[Electronics, Television &amp; Video, Streaming Me...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Streaming Media Players</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63617</th>\n",
       "      <td>AFZXSUCRYI2REEOY6WDM32GNAGWA</td>\n",
       "      <td>B000021YU8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>942565450000</td>\n",
       "      <td>Olympus Stylus Epic QD CG Date 35mm Camera</td>\n",
       "      <td>Olympus</td>\n",
       "      <td>[Electronics, Camera &amp; Photo, Film Photography...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Point &amp; Shoot Film Cameras</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779636</th>\n",
       "      <td>AFZ2RQH65E3ZYPP6UWHHWBZPFEYQ</td>\n",
       "      <td>B00002SWUE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>942986043000</td>\n",
       "      <td>Philips HDR112 Tivo Digital Video Recorder</td>\n",
       "      <td>PHILIPS</td>\n",
       "      <td>[Electronics, Television &amp; Video, Streaming Me...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Streaming Media Players</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673857</th>\n",
       "      <td>AHTQFIGJM4KTAA2S6OY6JN6LF2LA</td>\n",
       "      <td>B00000JFIF</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943652529000</td>\n",
       "      <td>Olympus D-340R 1.2MP Digital Camera</td>\n",
       "      <td>Olympus</td>\n",
       "      <td>[Electronics, Camera &amp; Photo, Digital Cameras,...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Point &amp; Shoot Digital Cameras</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           reviewerID        asin  overall  unixReviewTime  \\\n",
       "1190044  AENJWAP4JGEFZGDCTSX72UQ6M7IQ  B00000JDHV      4.0    940168313000   \n",
       "1236487  AHILMS23CHY27DIIEOPI3EHMRXAQ  B00002ST80      2.0    941867224000   \n",
       "63617    AFZXSUCRYI2REEOY6WDM32GNAGWA  B000021YU8      5.0    942565450000   \n",
       "779636   AFZ2RQH65E3ZYPP6UWHHWBZPFEYQ  B00002SWUE      5.0    942986043000   \n",
       "1673857  AHTQFIGJM4KTAA2S6OY6JN6LF2LA  B00000JFIF      5.0    943652529000   \n",
       "\n",
       "                                               title      brand  \\\n",
       "1190044  3Com 00371800 HomeConnect PC Digital Camera         HP   \n",
       "1236487         ReplayTV 2020 Digital Video Recorder  Replay Tv   \n",
       "63617     Olympus Stylus Epic QD CG Date 35mm Camera    Olympus   \n",
       "779636    Philips HDR112 Tivo Digital Video Recorder    PHILIPS   \n",
       "1673857          Olympus D-340R 1.2MP Digital Camera    Olympus   \n",
       "\n",
       "                                                categories  positive  user_id  \\\n",
       "1190044  [Electronics, Computers & Accessories, Compute...         1        2   \n",
       "1236487  [Electronics, Television & Video, Streaming Me...         0        3   \n",
       "63617    [Electronics, Camera & Photo, Film Photography...         1        4   \n",
       "779636   [Electronics, Television & Video, Streaming Me...         1        5   \n",
       "1673857  [Electronics, Camera & Photo, Digital Cameras,...         1        6   \n",
       "\n",
       "         item_id  brand_id                  main_category  main_category_id  \n",
       "1190044        2         2                        Webcams                 2  \n",
       "1236487        3         3        Streaming Media Players                 3  \n",
       "63617          4         4     Point & Shoot Film Cameras                 4  \n",
       "779636         5         5        Streaming Media Players                 3  \n",
       "1673857        6         4  Point & Shoot Digital Cameras                 5  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b24b15c1-2409-450b-b52b-d964b04bb276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving categorical processed data...\n",
      "This consists of (Target variable + Categorical (user, item, brand, main_category) IDs)\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving categorical processed data...\")\n",
    "\n",
    "# We'll call these '_categorical' to distinguish them from the final vectors\n",
    "train_df.to_parquet('../data/train_categorical.parquet', index=False)\n",
    "val_df.to_parquet('../data/val_categorical.parquet', index=False)\n",
    "test_df.to_parquet('../data/test_categorical.parquet', index=False)\n",
    "\n",
    "print(\"This consists of (Target variable + Categorical (user, item, brand, main_category) IDs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef284ed-41f7-4939-a5c9-aae4d5a67d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RecSys)",
   "language": "python",
   "name": "venv-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73102e2a-68c0-4be5-9690-0552ae7ede2b",
   "metadata": {},
   "source": [
    "## 07: Text Vectorization\n",
    "Convert the product title (e.g., \"Logitech C920x HD Pro Webcam\") into a list of 384 numbers (a vector) that captures its meaning.\n",
    "\n",
    "This is what allows our \"Content Tower\" to understand that \"Webcam\" and \"Camera\" are similar, even if they have different item IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e453be-59c4-4604-aa54-215d985f8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cca576f-d996-4131-b438-a0d7eda9a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint data...\n",
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load the Checkpoint Data ---\n",
    "print(\"Loading checkpoint data...\")\n",
    "train_full = pd.read_parquet('../data/train_categorical.parquet')\n",
    "val_full = pd.read_parquet('../data/val_categorical.parquet')\n",
    "test_full = pd.read_parquet('../data/test_categorical.parquet')\n",
    "print(\"Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503415d3-d1ff-4a8c-9fbf-a31cca611068",
   "metadata": {},
   "source": [
    "reduce the dataset size. proving the concept and building the pipeline is more important than the volume of data. Dropping from 2 Million rows to 100,000 rows.\n",
    "\n",
    "Run vectorization on 100K rows dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709d1a04-2066-47dd-a19a-d9f54dbca3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a MINI dataset for rapid prototyping...\n",
      "New Training Size: 80000 rows (was 1600000)\n",
      "New Validation Size: 10000 rows\n",
      "New Test Size: 10000 rows\n"
     ]
    }
   ],
   "source": [
    "# --- 2. THE FIX: Create a \"Mini\" Dataset (5% of data) ---\n",
    "print(\"\\nCreating a MINI dataset for rapid prototyping...\")\n",
    "# We take 5% of the data (approx 80k train, 10k val, 10k test)\n",
    "# random_state=42 ensures we get the same random rows every time\n",
    "train_df = train_full.sample(frac=0.05, random_state=42)\n",
    "val_df = val_full.sample(frac=0.05, random_state=42)\n",
    "test_df = test_full.sample(frac=0.05, random_state=42)\n",
    "\n",
    "print(f\"New Training Size: {len(train_df)} rows (was {len(train_full)})\")\n",
    "print(f\"New Validation Size: {len(val_df)} rows\")\n",
    "print(f\"New Test Size: {len(test_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0db7765-676e-4ed5-87bb-7bb231a8c93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Model...\n",
      "Using device: cpu\n",
      "\n",
      "--- Starting Vectorization on MINI dataset ---\n",
      "Processing Train Set...\n",
      "Encoding 80000 titles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b0e9295f124f618f92a41ba5eac2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Val Set...\n",
      "Encoding 10000 titles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e04a61a86a46e084e278aafc7492e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Test Set...\n",
      "Encoding 10000 titles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac0f7c39db471e80eff8be934838b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. Setup Model ---\n",
    "print(\"\\nLoading Model...\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# --- 4. Vectorize ---\n",
    "def encode_titles_column(df, column_name='title'):\n",
    "    print(f\"Encoding {len(df)} titles...\")\n",
    "    titles_list = df[column_name].tolist()\n",
    "    vectors = model.encode(titles_list, show_progress_bar=True, batch_size=64)\n",
    "    return list(vectors)\n",
    "\n",
    "print(\"\\n--- Starting Vectorization on MINI dataset ---\")\n",
    "\n",
    "print(\"Processing Train Set...\")\n",
    "train_df['title_vector'] = encode_titles_column(train_df)\n",
    "\n",
    "print(\"Processing Val Set...\")\n",
    "val_df['title_vector'] = encode_titles_column(val_df)\n",
    "\n",
    "print(\"Processing Test Set...\")\n",
    "test_df['title_vector'] = encode_titles_column(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769137e-3c93-4257-adfb-1c4c6901e955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "445af231-da25-4657-8d19-e3fed8cf55bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving MINI files...\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Save the FINAL Mini Files ---\n",
    "print(\"\\nSaving MINI files...\")\n",
    "# We save these as 'mini' so we know they are the small version\n",
    "train_df.to_parquet('../data/100k/train_final_mini.parquet', index=False)\n",
    "val_df.to_parquet('../data/100k/val_final_mini.parquet', index=False)\n",
    "test_df.to_parquet('../data/100k/test_final_mini.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb40f2b-e60d-4119-8c4e-af043502977a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541200    [-0.055413358, -0.030980006, 0.054996975, 0.00...\n",
       "750       [0.021162007, 0.03409558, -0.048250135, -0.000...\n",
       "766711    [0.026660616, 0.035521336, -0.058954343, -0.00...\n",
       "285055    [-0.08367935, 0.09948159, -0.027692752, -0.016...\n",
       "705995    [-0.010657759, 0.0041562063, 0.040858876, -0.0...\n",
       "Name: title_vector, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['title_vector'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e946c2-5c36-4330-bdcf-a025df071541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RecSys)",
   "language": "python",
   "name": "venv-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
